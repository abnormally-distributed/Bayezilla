---
title: "R Notebook"
output: html_notebook
---

Load the package..
```{r}
library(Bayezilla)
```
N <- 30
P <- 15
betas = c(.89, -.56, .11, .4, 1.99, -.84, -3.51, -.04, .08, 
          -4.18113776, -.035, .05, -.3, .14, -2.9364)
mu <- 0
set.seed(101)
X = MASS::mvrnorm(N, mu = rep(0, P), Sigma = rcorr(P), empirical = TRUE)
X = as.matrix(scale(X))
y = scale(mu + as.vector(X %*% matrix(betas, ncol = 1)))
betas = Bayezilla::lmSolve(y ~ ., cbind.data.frame(y = y, X))[-1]
noise = runif(N, -.12, .12)
y = scale(mu + as.vector(X %*% matrix(betas, ncol = 1)) + rnorm(N, 0, .25))
X = scale(X + matrix(rep(sort(noise), P), N, P))
data = cbind.data.frame(y, X)
colnames(data) = c("y", paste0("X", 1:P))



```{r eval=FALSE, include=FALSE}
data(demo.dat)
```

Let's first take a look at the classical linear model.

```{r echo=FALSE}
broom::tidy(lm(y ~ ., data)) %>% mutate_if(is.numeric, round, 3)
lmcoefs = broom::tidy(lm(y ~ ., data)) %>% mutate_if(is.numeric, round, 3)
```

Bayes GLM 

```{r echo = FALSE, message=FALSE, warning=FALSE}
out1 = glmBayes(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out2 = RR(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out3 = GRR(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out4 = blasso(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out5 = extLASSO(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out6 = negLASSO(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out7 = adaLASSO(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out8 = bayesEnet(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out9 = adaEnet(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
out10 = gdp(y ~ ., data, log_lik = TRUE, cl = makeCluster(4), iter = 4000)
```



```{r}
ests = data.frame(true = round(betas, 2), 
           lm = round(lmcoefs,2), 
           glmBayes = post_summary(out1, keeppars = c("Intercept", "beta"))$median,
           RR = post_summary(out2, keeppars = c("Intercept", "beta"))$median,
           GRR = post_summary(out3, keeppars = c("Intercept", "beta"))$median,
           blasso = post_summary(out4, keeppars = c("Intercept", "beta"))$median,
           extLASSO = post_summary(out5, keeppars = c("Intercept", "beta"))$median,
           negLASSO = post_summary(out6, keeppars = c("Intercept", "beta"))$median,
           adaLASSO = post_summary(out7, keeppars = c("Intercept", "beta"))$median,
           bayesEnet = post_summary(out8, keeppars = c("Intercept", "beta"))$median,
           adaEnet = post_summary(out9, keeppars = c("Intercept", "beta"))$median,
           gdp = post_summary(out10, keeppars = c("Intercept", "beta"))$median)

knitr::kable(ests, "markdown")
```



```{r}
true.betas = round(c(
  0.2927551, 0, -2.853434, 0, 0, 0.84, 0.32,
  0, -0.51, 0, 1.09113776, -0.89273929, 0.271721614, 0,
  -0.25, -1.18113776, -0.9273929, 0.72321414, 3.43034, 0, 0,
  0, 0, -2.3, 1.1, 0, -0.033604, -0.353825816,
  0, 0, 0, -0.03968, 0, 0.06324, 0,
  -0.13530108224, 0.11069967196, -0.033693480136, 0, 0, -0.14646108224, 0,
  -0.08967855336, -0.05336216, 0, 0, 0, 0, 0.2852,
  -0.1364
), 3)
coefTable = data.frame(
trueBetas = true.betas,
OLS = lmcoefs[-1],
BayesGLM = coefs1,
extendedBLASSO = coefs3,
negBLASSO = coefs4,
BayesElasticNet = coefs5
)

coefTable

EstimationError = cbind.data.frame(
  OLS = sum(abs(lmcoefs[-1] - true.betas)),
  BayesGLM = sum(abs(coefs1 - true.betas)),
  extendedBLASSO = sum(abs(coefs3 - true.betas)),
  negBLASSO = sum(abs(coefs4 - true.betas)),
  BayesElasticNet = sum(abs(coefs5 - true.betas))
)

EstimationError
```

2,