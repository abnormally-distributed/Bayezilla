% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaBLASSO.R
\name{adaBLASSO}
\alias{adaBLASSO}
\title{Adaptive Bayesian Lasso}
\usage{
adaBLASSO(formula, data, log_lik = FALSE, iter = 10000,
  warmup = 1000, adapt = 2000, chains = 4, thin = 1,
  method = "parallel", cl = makeCluster(2), ...)
}
\arguments{
\item{formula}{the model formula}

\item{data}{a data frame.}

\item{log_lik}{Should the log likelihood be monitored? The default is FALSE.}

\item{iter}{How many post-warmup samples? Defaults to 10000.}

\item{warmup}{How many warmup samples? Defaults to 1000.}

\item{adapt}{How many adaptation steps? Defaults to 2000.}

\item{chains}{How many chains? Defaults to 4.}

\item{thin}{Thinning interval. Defaults to 1.}

\item{method}{Defaults to "parallel". For an alternative parallel option, choose "rjparallel" or. Otherwise, "rjags" (single core run).}

\item{cl}{Use parallel::makeCluster(# clusters) to specify clusters for the parallel methods. Defaults to two cores.}

\item{...}{Other arguments to run.jags.}
}
\value{
a runjags object
}
\description{
The Bayesian LASSO of Leng, Tran and David Nott (2018). Basically just the Bayesian Lasso of Park & Casella (2008) but with
individual lambdas on each parameter defined by a gamma(r, d) distribution, where r and d are hyperparameters. Here r and d
are given independent gamma(0.0001, 0.0001) priors which approximates a Jeffrey's prior. For alternatives that may peform better
see \code{\link[Bayezilla]{negLASSO}} or \code{\link[Bayezilla]{extLASSO}}. However this is provided for a rich choice of options,
as it is sometimes hard to tell a priori which LASSO variant will work the best.
}
\examples{
adaBLASSO()

}
\references{
Park, T., & Casella, G. (2008). The Bayesian Lasso. Journal of the American Statistical Association, 103(482), 681-686. Retrieved from http://www.jstor.org/stable/27640090 \cr
Leng, C., Tran, M.N., & Nott, D.J. (2014). Bayesian adaptive Lasso. arXiv:1009.2300 \cr
}
