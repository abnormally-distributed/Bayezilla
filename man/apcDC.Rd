% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/apcDC.R
\name{apcDC}
\alias{apcDC}
\title{Adaptive Powered Correlation Prior with design covariates}
\usage{
apcDC(formula, design.formula, data, family = "gaussian", lower = NULL,
  upper = NULL, log_lik = FALSE, iter = 15000, warmup = 5000,
  adapt = 5000, chains = 4, thin = 1, method = "parallel",
  cl = makeCluster(2), ...)
}
\arguments{
\item{formula}{the model formula}

\item{design.formula}{the formula for the design covariates}

\item{data}{a data frame}

\item{family}{one of "gaussian", "binomial", or "poisson".}

\item{lower}{lower limit on value of lambda. Is NULL by default and limits are set based on the minimum value that produces a positive definite covariance matrix.}

\item{log_lik}{Should the log likelihood be monitored? The default is FALSE.}

\item{iter}{How many post-warmup samples? Defaults to 15000.}

\item{warmup}{How many warmup samples? Defaults to 5000.}

\item{adapt}{How many adaptation steps? Defaults to 5000.}

\item{chains}{How many chains? Defaults to 4.}

\item{thin}{Thinning interval. Defaults to 1.}

\item{method}{Defaults to "parallel". For an alternative parallel option, choose "rjparallel". Otherwise, "rjags" (single core run).}

\item{cl}{Use parallel::makeCluster(# clusters) to specify clusters for the parallel methods. Defaults to two cores.}

\item{...}{Other arguments to run.jags.}

\item{uppper}{upper limit on value of lambda. Is NULL by default and limits are set based on the maximum value that produces a positive definite covariance matrix.}
}
\value{
A run.jags object.
}
\description{
The adaptive powered correlation prior extends the Zellner-Siow Cauchy g-prior by allowing the crossproduct of the 
model matrix to be raised to powers other than -1 (which gives the Fisher information matrix). The power here will 
be referred to as "lambda". A lambda of 0 results in an identity matrix, which results in a ridge-regression like
prior. Positive values of lambda adapt to collinearity by allowing correlated predictors to enter and exit the model 
together. Negative values of lambda on the other hand favor including only one of a set of correlated predictors. 
This can be understood as projecting the information matrix into a new space which leads to a model
similar in function to principal components regression (Krishna et al., 2009). In this implementation full Bayesian
inference is used for lambda, rather than searching via marginal likelihood maximization as Krishna et al. (2009) did. 
The reason for this is twofold. First, full Bayesian inference means the model has to be fit only once instead of
several times over a grid of candidate values for lambda. Second, this avoids any coherency problems such as those
that arise when using fixed-g priors. \cr
\cr
In addition, this function allows for a set of covariates that are held constant across all models.  
For example, you may wish to keep variables such as age and gender constant in order to control for them,
so that the selected variables are chosen in light of the effects of age and gender on the outcome variable. \cr
\cr
The model specification is given below. Note that the model formulae have been adjusted to reflect the fact that JAGS
parameterizes the normal and multivariate normal distributions by their precision, rater than (co)variance. 
For generalized linear models plug-in pseudovariances are used. 
\cr
\cr
\cr
\if{html}{\figure{apcDC.png}{}}
\if{latex}{\figure{apcDC.png}{}}
\cr
\cr
Plugin Pseudo-Variances: \cr
\if{html}{\figure{pseudovar.png}{}}
\if{latex}{\figure{pseudovar.png}{}}
}
\examples{
apcDC()

}
\references{
Krishna, A., Bondell, H. D., & Ghosh, S. K. (2009). Bayesian variable selection using an adaptive powered correlation prior. Journal of statistical planning and inference, 139(8), 2665â€“2674. doi:10.1016/j.jspi.2008.12.004
}
