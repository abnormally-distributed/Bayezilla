% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glmBayes.R
\name{glmBayes}
\alias{glmBayes}
\title{Bayesian Basic GLMs}
\usage{
glmBayes(formula, data, family = "gaussian", log_lik = FALSE,
  iter = 10000, warmup = 1000, adapt = 2000, chains = 4,
  thin = 1, method = "parallel", cl = makeCluster(2), ...)
}
\arguments{
\item{formula}{the model formula}

\item{data}{a data frame}

\item{family}{one of "gaussian", "binomial", or "poisson".}

\item{log_lik}{Should the log likelihood be monitored? The default is FALSE.}

\item{iter}{How many post-warmup samples? Defaults to 10000.}

\item{warmup}{How many warmup samples? Defaults to 1000.}

\item{adapt}{How many adaptation steps? Defaults to 2000.}

\item{chains}{How many chains? Defaults to 4.}

\item{thin}{Thinning interval. Defaults to 1.}

\item{method}{Defaults to "parallel". For an alternative parallel option, choose "rjparallel" or. Otherwise, "rjags" (single core run).}

\item{cl}{Use parallel::makeCluster(# clusters) to specify clusters for the parallel methods. Defaults to two cores.}

\item{...}{Other arguments to run.jags.}
}
\value{
A run.jags object
}
\description{
This model utilizes normal-gamma mixture priors. A student-t prior can be parameterized as a norma-gamma mixture 
by utilizing a gamma(df/2, df/2) distribution where df is the desired degrees of freedom. 
This model utilizes a single degree of freedom, which gives marginal cauchy distributions. The cauchy distribution has no defined 
first or second moments (mean and variance), hence does not require subjective specification of the prior means. The cauchy
distribution's extremely long tails allow coefficients with strong evidence of being large to not be shrunk too strongly, while the 
large probability mass at the mode of zero captures small noisy coefficients and regularizes them. The scale is modeled as a single hyperparameter "omega" via the gamma(.5, .5)
prior and this pooled-scale induces shrinkage when neccessary. 
This setup yields an ideal proper reference / objective prior that is data-driven and adaptive.
}
\details{
Standard gaussian, binomial, and poisson likelihood functions are available.

Note that if you do not scale and center your numeric predictors, this will likely not perform well or
give reasonable results. The mixing hyperparameter omega assumes all covariates are on the same scale.
For an alternative proper reference prior see \code{\link[Bayezilla]{apcGlm}}
}
\examples{
glmBayes()

}
\seealso{
\code{\link[Bayezilla]{apcGlm}}
}
