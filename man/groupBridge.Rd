% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/groupBridge.R
\name{groupBridge}
\alias{groupBridge}
\title{Bayesian Group Bridge Regression}
\usage{
groupBridge(X, y, idx, family = "gaussian", kappa = 1.4,
  log_lik = FALSE, iter = 10000, warmup = 1000, adapt = 2000,
  chains = 4, thin = 1, method = "parallel", cl = makeCluster(2),
  ...)
}
\arguments{
\item{X}{the model matrix. Construct this manually with model.matrix()[,-1]}

\item{y}{the outcome variable}

\item{idx}{the group labels. Should be of length = to ncol(model.matrix()[,-1]) with the group assignments
for each covariate. Please ensure that you start numbering with 1, and not 0.}

\item{family}{one of "gaussian", "binomial", or "poisson".}

\item{kappa}{the Lp norm you wish to utilize. Default is 1.4.}

\item{log_lik}{Should the log likelihood be monitored? The default is FALSE.}

\item{iter}{How many post-warmup samples? Defaults to 10000.}

\item{warmup}{How many warmup samples? Defaults to 1000.}

\item{adapt}{How many adaptation steps? Defaults to 2000.}

\item{chains}{How many chains? Defaults to 4.}

\item{thin}{Thinning interval. Defaults to 1.}

\item{method}{Defaults to "parallel". For an alternative parallel option, choose "rjparallel" or. Otherwise, "rjags" (single core run).}

\item{cl}{Use parallel::makeCluster(# clusters) to specify clusters for the parallel methods. Defaults to two cores.}

\item{...}{Other arguments to run.jags.}
}
\value{
a runjags object
}
\description{
The Group Bayesian Bridge model of Mallick & Yi (2018). Bridge regression allows you to utilize different Lp norms for the shape 
of the prior through the shape parameter kappa of the power exponential distribution (also known as generalized Gaussian). 
Norms of 1 and 2 give the Laplace and Gaussian distributions respectively (corresponding to the LASSO and Ridge Regression). 
Norms smaller than 1 are very difficult to estimate directly, but have very tall modes at zero and very long, cauchy like tails. 
Values greater than 2 become increasingly platykurtic, with the uniform distribution arising as it approaches infinity. \cr 
\cr
Using kappa = 1 yields the New Bayesian Group LASSO, which is a re-parameterization of the Bayesian Group LASSO utilizing a scale mixture of
uniform distributions to obtain the Laplacian priors (Mallick & Yi, 2014). The key difference the Bayesian Group Bridge or New Bayesian Group LASSO
has from the Group LASSO presented in Kyung et al. (2010) is that each group is here given its own lambda, faithful to the Mallick & Yi (2018) model.\cr
\cr
JAGS has no built in power exponential distribution, so the distribution is parameterized as a uniform-gamma mixture just as in Mallick & Yi (2018). 
The parameterization is given below. For generalized linear models plug-in pseudovariances are used. \cr
\cr
Model Specification:
\cr
\if{html}{\figure{groupBridge.png}{}}
\if{latex}{\figure{groupBridge.png}{}}

\cr
Plugin Pseudo-Variances: \cr
\if{html}{\figure{pseudovar.png}{}}
\if{latex}{\figure{pseudovar.png}{}}
}
\examples{
groupBridge()

}
\references{
\cr
Kyung, M., Gill, J., Ghosh, M., and Casella, G. (2010). Penalized regression, standard errors, and bayesian lassos. Bayesian Analysis, 5(2):369–411.\cr
\cr
Mallick, H. & Yi, N. (2018) Bayesian bridge regression, Journal of Applied Statistics, 45:6, 988-1008, DOI: 10.1080/02664763.2017.1324565 \cr
\cr
Mallick, H., & Yi, N. (2014). A New Bayesian Lasso. Statistics and its interface, 7(4), 571–582. doi:10.4310/SII.2014.v7.n4.a12 \cr
}
