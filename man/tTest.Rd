% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tTest.R
\name{tTest}
\alias{tTest}
\title{Bayesian 't-tests'}
\usage{
tTest(formula = NULL, data, like.func = "normal", compval = 0,
  model = "is", iter = 10000, warmup = 2500, adapt = 2500,
  chains = 4, thin = 3, method = "parallel", cl = makeCluster(2),
  summarise = FALSE, ...)
}
\arguments{
\item{formula}{If using an independent samples t-test, supply a formula of the form y ~ group}

\item{data}{the data frame containing the outcome variable and group labels for independent samples t-test. 
If using the one sample t-test, the vector of observations. 
If using repeated measures, the vector of group differences.}

\item{like.func}{the likelihood function to use. either "normal" (the default) or "student_t"}

\item{compval}{the hypothesized null value for a one sample t-test}

\item{model}{one of "is" (independent samples t-test) , "rm" (repeated measures t-test), or "os" (one sample t-test)}

\item{iter}{the number of iterations. defaults to 10000.}

\item{warmup}{number of burnin samples. defaults to 2500.}

\item{adapt}{number of adaptation steps. defaults to 2500.}

\item{chains}{number of chains. defaults to 4.}

\item{thin}{the thinning interval. defaults to 3.}

\item{method}{Defaults to "parallel". For an alternative parallel option, choose "rjparallel" or. Otherwise, "rjags" (single core run).}

\item{cl}{Use parallel::makeCluster(# clusters) to specify clusters for the parallel methods. Defaults to two cores.}

\item{...}{other arguments to run.jags}
}
\value{
a runjags object
}
\description{
Two different likelihood functions are offered. For the normal likelihood, a conjugate normal-gamma model:

   For unit scaled and centered response variables this implies gamma(.001, .001)
   
   tau_i ~ dgamma(square(prec(y)) / 1000, prec(y) / 1000)
   
   For unit scaled response variables this implies normal(0, .5) or normal(0, sigma = 1.414214)
   
   mu_i ~ normal(0, .5 * prec(y)) 
   
   y ~ normal(mu_i, tau_i)
       
For the Student-t likelihood: 

   nu ~ gamma(2, .01)
   
   For unit scaled and centered response variables this implies half-t(0, 1, 3) on the standard deviation
   
   tau_i ~ scaled.gamma(ysd, 3)
   
   For unit scaled response variables this implies cauchy(0, .5) or equivalently, cauchy(0, sigma = 1.414214)
   
   mu_i ~ cauchy(0, .5 * 1/var(y))           
   
   y ~ t(mu_i, tau_i, nu)


Note the use of a student-t likelihood is wholly unrelated to this being analagous to the frequentist t-test.
In the t-test, the student-t distribution is the asymptotic sampling distribution of the t-statistic,
but here it is used to model the heaviness of the tails in the data. The estimation of nu in fact does nothing
to bias results when there is not sufficient evidence of non-normality. It could well be used as a default
in estimating the means, however, the student-t likelihood does not have conjugate priors. JAGS makes considerable
gains in speed when using conjugate exponential family priors, so I have opted to set the normal likelihood as 
the default.

INDEPENDENT SAMPLES T-TEST: 

The difference in means is modeled as mu_1 - mu_2. The difference in the standard deviations of both groups
is modeled as sqrt(1/tau_1 - 1/tau_2).

The log-Bayes Factor is estimated as the  difference in log density of the effect evaluated at zero and the log density evaluated
at each point within the posterior distribution (the Savage-Dickey ratio method). It is presented on the log-density scale for
numerical stability. Note that the log-Bayes Factor is here presented as the log-evidence in favor of the alternative hypothesis.
Hence, a larger log-BF is evidence in favor of a non-zero difference. Use the median Bayes Factor if you use the median as your point estimate, and the mean if using the posterior mean as your point estimate. 

Several effect size measures are also provided. A quantity variously known as Cohen's d or Hedge's g (1981)* is given as the primary effect size measure.
Due to the ambiguity in which term is correct, it is simply labeled as "effSize" in the output. The specific formula used is given below: 

\deqn{\sqrt{\frac{\left[\sigma_{1}^{2} \times\left(n_{1}-1\right)\right]+\left[\sigma_{2}^{2} \times\left(n_{2}-1\right)\right]}{n_{1}+n_{2}-2}}}

This formula for the effect size is robust to differences in the variances across groups.

Cohen's U3 (1977) is defined as a measure of non-overlap, which quantifies the percentage of data points
in group A that are smaller than the median of group B. It is given by the probability density below the observed effect size via the normal cumulative
distribution function; phi(effSize). 

A similar measure of effect size known as the probability of superiority, or alternatively the common language effect size (CLES), is given by the effect size
divided by the square root of two entered into the normal cumulative distribution function; phi(effSize / sqrt(2)). It is very similar in size to Cohen's U3 and 
carries a similar meaning, but is more strightforward. The CLES gives the probability that an observation sampled at random from group A will have a higher value 
than an observation sampled at random from group B. The common language effect size was developed to facilitate an easy way to explain the importance of a statistical 
result to the layman who may not have an intuition for Cohen's d or Hedge's g, which are defined as changes in standard deviation. It is labeled "CL" in the posterior output. 

Finally, the output contains posterior predictive simulations for each participant (column-wise). The row-wise posterior predictive distribution gives simulated samples of size N 
that allow you to visualize what future data sets of the same size might look like.   
        
*The labels Cohen's d and Hedge's g have both been applied to various measures of effect size. See the citation below for a discussion of this.
        
        Difference between Cohen's d and Hedges' g for effect size metrics, URL (version: 2018-09-28): https://stats.stackexchange.com/q/338043


REPEATED MEASURES T-TEST:

Much of the information is the same as above, except Cohen's U3 is not provided as it lacks an intuitive definition for this case. 

The effect size is simply the standardized mean difference (z-score) 

ONE SAMPLE T-TEST:

Same as above, but the CLES is also dropped because it is not applicable to one group. The effect size is calculated as the mean of y - the comparison value  / sd(y)
}
\examples{
tTest(len ~ supp, ToothGrowth)

}
